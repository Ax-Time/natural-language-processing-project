{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we tried to fine tuned a gpt2 model with the wow dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT fine-tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data for train, validation and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Base_directory\n",
    "base_dir = './wizard_of_wikipedia/'\n",
    "\n",
    "# Load the data\n",
    "with open(base_dir + 'train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(base_dir + 'valid_random_split.json') as f:\n",
    "    valid_data = json.load(f)\n",
    "with open(base_dir + 'test_random_split.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started from this gpt model loaded from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTNeoForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"EleutherAI/gpt-neo-125M\"\n",
    "\n",
    "# default_device = 'cpu'\n",
    "default_device = 'mps' # apple silicon\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else default_device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "model = GPTNeoForCausalLM.from_pretrained('./model').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_checked_sentence(utterance):\n",
    "    try:\n",
    "        checked_sentence = list(utterance['checked_sentence'].values())[0]\n",
    "        return 'PASSAGE: ' + checked_sentence + '\\n'\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def parse_dialog(dialog):\n",
    "        return '\\n'.join([\n",
    "            f'SPEAKER: {utterance[\"speaker\"]}\\n' + \\\n",
    "            extract_checked_sentence(utterance) + \\\n",
    "            f'TEXT: {utterance[\"text\"]}\\n'\n",
    "        for utterance in dialog])\n",
    "\n",
    "def parse_data(dataset):\n",
    "    return [\n",
    "        f'CHOSEN_TOPIC: {sample[\"chosen_topic\"]}\\n' + \\\n",
    "        f'PERSONA: {sample[\"persona\"]}\\n' + \\\n",
    "        parse_dialog(sample['dialog'])\n",
    "    for sample in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parsed = parse_data(train_data)\n",
    "valid_parsed = parse_data(valid_data)\n",
    "test_parsed = parse_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_parsed = Dataset.from_dict({'text': train_parsed})\n",
    "valid_parsed = Dataset.from_dict({'text': valid_parsed})\n",
    "test_parsed = Dataset.from_dict({'text': test_parsed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "data = DatasetDict()\n",
    "data['train'] = train_parsed\n",
    "data['validation'] = valid_parsed\n",
    "data['test'] = test_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.48ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22ba/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    input_encodings = tokenizer(examples[\"text\"], padding=True, truncation=True)\n",
    "    sample = {\n",
    "        'input_ids': input_encodings.input_ids\n",
    "    }\n",
    "    return sample\n",
    "\n",
    "tokenized_data = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"cooler_trainer_name\", \n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=6.25e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    per_device_eval_batch_size=1,\n",
    "    use_mps_device=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=tokenized_data['train'], \n",
    "    eval_dataset=tokenized_data['validation'],\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model on a some sentences of the test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT as the wizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the answer given from the parlai module to be compared with the gpt answer\n",
    "def get_model_answer(dialogue):\n",
    "    dialogue = dialogue.split('\\n')\n",
    "    for i in range(len(dialogue)):\n",
    "        if dialogue[i].startswith('SPEAKER: 0_Wizard') or dialogue[i].startswith('SPEAKER: 1_Wizard'):\n",
    "            return dialogue[i+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the first wizard's answer\n",
    "def get_gpt_answer(dialogue):\n",
    "    dialogue = dialogue.split('\\n')\n",
    "    gpt_input = dialogue[0]\n",
    "    for i in range(1, len(dialogue)):\n",
    "        gpt_input = gpt_input + '\\n' + dialogue[i]\n",
    "        if dialogue[i].startswith('SPEAKER: 0_Wizard') or dialogue[i].startswith('SPEAKER: 1_Wizard'):\n",
    "            gpt_input = gpt_input + '\\n' + dialogue[i+1] + '\\n'\n",
    "            break\n",
    "    \n",
    "    output_len = len(gpt_input) + 100\n",
    "    gpt_input = tokenizer(gpt_input, return_tensors='pt').input_ids.to(device)\n",
    "    gpt_output = model.generate(gpt_input, pad_token_id=tokenizer.eos_token_id, do_sample=True, max_length=output_len, top_p=0.95, top_k=60)\n",
    "    gpt_output = tokenizer.decode(gpt_output[0], skip_special_tokens=True)\n",
    "    gpt_output = gpt_output.split('\\n')\n",
    "\n",
    "    for i in range(len(gpt_output)):\n",
    "        if gpt_output[i].startswith('SPEAKER: 0_Wizard') or gpt_output[i].startswith('SPEAKER: 1_Wizard'):\n",
    "            return gpt_output[i+2]\n",
    "\n",
    "    return ''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model answer:  I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts.\n",
      "GPT answer:  I enjoy Science Fiction too, it is my favorite genre. \n",
      "\n",
      "Model answer:  No I could not! I couldn't imagine living when internet access was rare and very few people had it!\n",
      "GPT answer:  I cannot imagine, I think I would only be able to access news and news articles. The internet is faster when you can find news or info on a computer.  What do you need to go to while you are in the house?\n",
      "\n",
      "Model answer:  Yes, I perform administrative duties as a pharmacy technician.\n",
      "GPT answer:  I do! I just got out of the program and started looking for work. Are you a pharmacist? \n",
      "\n",
      "Model answer:  basically homebrewing is personal small scale beer  production\n",
      "GPT answer:  Do you ever brew?  Not necessarily for personal or non-commercial purposes.  Homebrewing seems to be quite popular these days.\n",
      "\n",
      "Model answer:  I know, it's a shame that red hair is only 1 to 2% of the population.\n",
      "GPT answer:  I feel like most red hair people are just doing it naturally. I think people have red hair in 1 to 2% of the human population.\n",
      "\n",
      "Model answer:  I don't know how to be romantic. I have trouble expressing emotional attraction.\n",
      "GPT answer:  I have been really attracted to someone, I know it can be hard when one is the most emotionally overwhelming person.\n",
      "\n",
      "Model answer:  Hello. I hope you might enjoy or know something about Krav Maga?\n",
      "GPT answer:  Krav Maga is my favourite thing to do. When I do  I really want to try the krav magas!\n",
      "\n",
      "Model answer:  i think most bank job require  require experience with handling\n",
      "GPT answer:  Yes,  Teller jobs have quite a bit of experience.\n",
      "\n",
      "Model answer:  I like parachunting or skydiving \n",
      "GPT answer:  Skydiving has been around for a very long time, I've been able to parachute into the ocean and experience it with my bare feet, before it spiraled into the earth, myself.\n",
      "\n",
      "Model answer:  sometimes, depending on the writer\n",
      "GPT answer:  I like to read true crime books. I read so many of the first stories. I'm pretty good at that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Model answer: ', get_model_answer(train_parsed[i])[6:])\n",
    "    print('GPT answer: ', get_gpt_answer(train_parsed[i])[6:])\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT as the apprentice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATION_LENGTH = 200\n",
    "\n",
    "test_index = [0, 5, 6, 12, 13, 19, 50]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for i in test_index:\n",
    "    train = train_parsed[i]['text']\n",
    "    split_train = train.split('\\n')\n",
    "    input = '\\n'.join(split_train[:5])\n",
    "    encoded_input = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "    encoded_output = model.generate(encoded_input, do_sample=True, max_length=GENERATION_LENGTH, top_p=0.95, temperature=0.85)\n",
    "    decoded_output = tokenizer.decode(encoded_output[0], skip_special_tokens=True)\n",
    "    output = decoded_output.split('\\n')\n",
    "    topic_output = []\n",
    "    topic_output.append(output[0])\n",
    "    topic_output.append(output[2])\n",
    "    topic_output.append(output[4])\n",
    "    topic_output.append(output[6:8])\n",
    "    outputs.append(topic_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHOSEN_TOPIC: Science fiction\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: I think science fiction is an amazing genre for anything. Future science, technology, time travel, FTL travel, they're all such interesting concepts. I don't want to be a total science person.\n",
      "['SPEAKER: 1_Apprentice', 'TEXT: I agree, I love science fiction. Have you ever watched it?']\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: Romance (love)\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: I don't know how to be romantic. I have trouble expressing emotional attraction. Do you enjoy romance?\n",
      "['SPEAKER: 1_Apprentice', 'TEXT: I love romance. It is the easiest way to get into love']\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: Krav Maga\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: Hello. I hope you might enjoy or know something about Krav Maga? It's a sport in which people try to keep their balance. Do you like it?\n",
      "['SPEAKER: 1_Apprentice', 'TEXT: I enjoy it too! I love krav maga!']\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: The Hershey Company\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: Hi there, I love chocolate, my favorite brand of chocolate is Hershey coming from my local city of Pennsylvania! \n",
      "['SPEAKER: 1_Apprentice', \"TEXT: I like Hershey's Chocolate it is great\"]\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: Divorce\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: Divorce laws vary by state and in most countries. Most require a court and a legal process with issues of alimony and child support and visitation. I was divorced in 2001. \n",
      "['SPEAKER: 1_Apprentice', \"TEXT: That is very long ago. I've heard that it is very common in some states to have people divorce and that people get more out of it than they would if they were married. What makes you want to get divorced?\"]\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: Fly fishing\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: I would like to try fly fishing  in fresh or salt water. So i will need to learn to fly the fly, its hard. Do you like to fly?\n",
      "['SPEAKER: 1_Apprentice', \"TEXT: I enjoy it also, but i don't know much about it. What kind of fish do you like to fish? \"]\n",
      "\n",
      "\n",
      "CHOSEN_TOPIC: Marathon\n",
      "SPEAKER: 0_Wizard\n",
      "TEXT: I love running marathons, all 26 miles! I'm a runner too! \n",
      "['SPEAKER: 1_Apprentice', 'TEXT: Me too. I have won a lot of marathons though, but only in part due to my running. What are some of your favorite runners?']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    for elem in output:\n",
    "        print(elem)\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exernal knoweledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHOSEN_TOPIC: AlphaZero', 'PERSONA: I am a chess enthusiast.', 'SPEAKER: 0_Wizard', 'PASSAGE: ', 'AlphaZero is a computer program developed by artificial intelligence research company DeepMind to master the games of chess, shogi and go. This algorithm uses an approach similar to AlphaGo Zero.', '', 'On December 5, 2017, the DeepMind team released a preprint paper introducing AlphaZero, which within 24 hours of training achieved a superhuman level of play in these three games by defeating world-champion programs Stockfish, Elmo, and the three-day version of AlphaGo Zero. In each case it made use of custom tensor processing units (TPUs) that the Google programs were optimized to use.[1] AlphaZero was trained solely via self-play using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the neural networks, all in parallel, with no access to opening books or endgame tables. After four hours of training, DeepMind estimated AlphaZero was playing chess at a higher Elo rating than Stockfish 8; after nine hours of training, the algorithm defeated Stockfish 8 in a time-controlled 100-game tournament (28 wins, 0 losses, and 72 draws).[1][2][3] The trained algorithm played on a single machine with four TPUs.', '', \"DeepMind's paper on AlphaZero was published in the journal Science on 7 December 2018;[4] however, the AlphaZero program itself has not been made available to the public.[5] In 2019, DeepMind published a new paper detailing MuZero, a new algorithm able to generalise AlphaZero's work, playing both Atari and board games without knowledge of the rules or representations of the game.[6]\", '', 'TEXT: AlphaZero is so impressive! When I first read it was far better at playing than the world champion I was astonished!', '', 'SPEAKER: 0_Wizard', 'PASSAGE: It is designed to have the \"strength\" and \"delight\" of playing against a very large and powerful opponent, but with the added bonus of providing speed and improved on-court control, which allows the winner to play more effectively against the eventual opponents with a much smaller opponent.', 'TEXT: It was so good at playing against a large opponent that it made the world champions the most powerful of the players.', '', 'SPEAKER: 1_Apprentice', 'TEXT: Yes, and it is one of the main reasons why I like to play chess. What is your favorite chess game?', '', 'SPEAKER: 0_Wizard', 'PASSAGE: The game is played on a single machine, with the goal of picking the best pieces from a set of 20 pieces that have a score at least 50% of the time, and the board is']\n"
     ]
    }
   ],
   "source": [
    "topic = 'AlphaZero'\n",
    "passage = \"\"\"\n",
    "AlphaZero is a computer program developed by artificial intelligence research company DeepMind to master the games of chess, shogi and go. This algorithm uses an approach similar to AlphaGo Zero.\n",
    "\n",
    "On December 5, 2017, the DeepMind team released a preprint paper introducing AlphaZero, which within 24 hours of training achieved a superhuman level of play in these three games by defeating world-champion programs Stockfish, Elmo, and the three-day version of AlphaGo Zero. In each case it made use of custom tensor processing units (TPUs) that the Google programs were optimized to use.[1] AlphaZero was trained solely via self-play using 5,000 first-generation TPUs to generate the games and 64 second-generation TPUs to train the neural networks, all in parallel, with no access to opening books or endgame tables. After four hours of training, DeepMind estimated AlphaZero was playing chess at a higher Elo rating than Stockfish 8; after nine hours of training, the algorithm defeated Stockfish 8 in a time-controlled 100-game tournament (28 wins, 0 losses, and 72 draws).[1][2][3] The trained algorithm played on a single machine with four TPUs.\n",
    "\n",
    "DeepMind's paper on AlphaZero was published in the journal Science on 7 December 2018;[4] however, the AlphaZero program itself has not been made available to the public.[5] In 2019, DeepMind published a new paper detailing MuZero, a new algorithm able to generalise AlphaZero's work, playing both Atari and board games without knowledge of the rules or representations of the game.[6]\n",
    "\"\"\"\n",
    "text = 'AlphaZero is so impressive! When I first read it was far better at playing than the world champion I was astonished!\\n'\n",
    "input = f'CHOSEN_TOPIC: {topic}\\n' \\\n",
    "    'PERSONA: I am a chess enthusiast.\\n' \\\n",
    "    'SPEAKER: 0_Wizard\\n' \\\n",
    "    f'PASSAGE: {passage}\\n' \\\n",
    "    f'TEXT: {text}'\n",
    "\n",
    "encoded_input = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "encoded_output = model.generate(encoded_input, do_sample=True, max_length=GENERATION_LENGTH*3, top_p=0.95, temperature=0.80)\n",
    "decoded_output = tokenizer.decode(encoded_output[0], skip_special_tokens=True)\n",
    "output = decoded_output.split('\\n')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: AlphaZero is so impressive! When I first read it was far better at playing than the world champion I was astonished!\n",
      "TEXT: It was so good at playing against a large opponent that it made the world champions the most powerful of the players.\n"
     ]
    }
   ],
   "source": [
    "print(output[10])\n",
    "print(output[14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
